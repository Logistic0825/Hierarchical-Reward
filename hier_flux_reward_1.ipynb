{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3crL0KXKPANE",
        "outputId": "75d98892-2b9b-4734-acef-94a1e49796ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ImageReward'...\n",
            "remote: Enumerating objects: 230, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 230 (delta 55), reused 51 (delta 43), pack-reused 133 (from 1)\u001b[K\n",
            "Receiving objects: 100% (230/230), 4.30 MiB | 4.80 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n",
            "Collecting image-reward\n",
            "  Downloading image_reward-1.5-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting timm==0.6.13 (from image-reward)\n",
            "  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: transformers>=4.27.4 in /usr/local/lib/python3.12/dist-packages (from image-reward) (4.55.4)\n",
            "Collecting fairscale==0.4.13 (from image-reward)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub>=0.13.4 in /usr/local/lib/python3.12/dist-packages (from image-reward) (0.34.4)\n",
            "Requirement already satisfied: diffusers>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from image-reward) (0.35.1)\n",
            "Requirement already satisfied: accelerate>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from image-reward) (1.10.1)\n",
            "Requirement already satisfied: datasets>=2.11.0 in /usr/local/lib/python3.12/dist-packages (from image-reward) (4.0.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fairscale==0.4.13->image-reward) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from fairscale==0.4.13->image-reward) (2.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm==0.6.13->image-reward) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm==0.6.13->image-reward) (6.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.16.0->image-reward) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.16.0->image-reward) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.16.0->image-reward) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.11.0->image-reward) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.11.0->image-reward) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.11.0->image-reward) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.11.0->image-reward) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.11.0->image-reward) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.11.0->image-reward) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.11.0->image-reward) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.11.0->image-reward) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.11.0->image-reward) (2025.3.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.16.0->image-reward) (8.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.16.0->image-reward) (2024.11.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.16.0->image-reward) (11.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.4->image-reward) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.4->image-reward) (1.1.8)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.27.4->image-reward) (0.21.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.11.0->image-reward) (3.12.15)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.11.0->image-reward) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.11.0->image-reward) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.11.0->image-reward) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.11.0->image-reward) (2025.8.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13->image-reward) (3.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers>=0.16.0->image-reward) (3.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.11.0->image-reward) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.11.0->image-reward) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.11.0->image-reward) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.11.0->image-reward) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.11.0->image-reward) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.11.0->image-reward) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.11.0->image-reward) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.11.0->image-reward) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.11.0->image-reward) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.11.0->image-reward) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.11.0->image-reward) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->fairscale==0.4.13->image-reward) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->fairscale==0.4.13->image-reward) (3.0.2)\n",
            "Downloading image_reward-1.5-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fairscale\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332208 sha256=994a2c5f5942e1167bf974016d46d8dc74628e9e0eead714d073d6d6095436e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/88/aa/d84b2cf1bad6b273cbf661640141a82c7b9f496e024f80aac0\n",
            "Successfully built fairscale\n",
            "Installing collected packages: fairscale, timm, image-reward\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.19\n",
            "    Uninstalling timm-1.0.19:\n",
            "      Successfully uninstalled timm-1.0.19\n",
            "Successfully installed fairscale-0.4.13 image-reward-1.5 timm-0.6.13\n"
          ]
        }
      ],
      "source": [
        "# Clone the ImageReward repository (containing data for testing)\n",
        "!git clone https://github.com/THUDM/ImageReward.git\n",
        "# !cd ImageReward\n",
        "\n",
        "# Install the integrated package `image-reward`\n",
        "!pip install image-reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6uAjAyGX2SJ",
        "outputId": "295ed727-0680-475d-faeb-65cd4f9ae799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clip\n",
            "  Downloading clip-0.2.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-0.2.0-py3-none-any.whl size=6989 sha256=7a43dd77d58cf622a18271f1b54f873305d2c0172cb77d1c16f56c1a7bfd532a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/fd/54/9d4e15cf829b871199a7cd3597e869a514d1624a0a43076896\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2D-1DqnYnrM",
        "outputId": "4b564c23-853c-41a6-d8b7-5946baaccfad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ImageReward\n"
          ]
        }
      ],
      "source": [
        "cd ImageReward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeUAss3CYpQN",
        "outputId": "5a10c299-dd39-41ad-97dd-efe282ecf866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t    ImageReward        refl_sdxl.py\t\t   sdwebui\n",
            "benchmark   LICENSE\t       requirements_refl_sdxl.txt  setup.py\n",
            "data\t    README.md\t       requirements_refl.txt\t   test-benchmark.py\n",
            "example.py  refl.py\t       requirements.txt\t\t   test.py\n",
            "figures     refl_sdxl_lora.py  scripts\t\t\t   train\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGF-eQKhFcBp"
      },
      "source": [
        "# 这是ImageReward demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5q5pjQ2O35C",
        "outputId": "28e9be8f-ee40-4285-a979-e98950c7889c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load checkpoint from /root/.cache/ImageReward/ImageReward.pt\n",
            "checkpoint loaded\n",
            "\n",
            "Preference predictions:\n",
            "\n",
            "ranking = [1, 2, 3, 4]\n",
            "rewards = [0.5811920166015625, 0.27452775835990906, -1.4158878326416016, -2.032486915588379]\n",
            "          1.webp: 0.58\n",
            "          2.webp: 0.27\n",
            "          3.webp: -1.42\n",
            "          4.webp: -2.03\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# import torch\n",
        "# import ImageReward as reward\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     prompt = \"a painting of an ocean with clouds and birds, day time, low depth field effect\"\n",
        "#     img_prefix = \"assets/images\"\n",
        "#     generations = [f\"{pic_id}.webp\" for pic_id in range(1, 5)]\n",
        "#     img_list = [os.path.join(img_prefix, img) for img in generations]\n",
        "#     # model = reward.load(\"ImageReward-v1.0\")\n",
        "#     # with torch.no_grad():\n",
        "#     #     ranking, rewards = model.inference_rank(prompt, img_list)\n",
        "#     #     # Print the result\n",
        "#     #     print(\"\\nPreference predictions:\\n\")\n",
        "#     #     print(f\"ranking = {ranking}\")\n",
        "#     #     print(f\"rewards = {rewards}\")\n",
        "#     #     for index in range(len(img_list)):\n",
        "#     #         score = model.score(prompt, img_list[index])\n",
        "#     #         print(f\"{generations[index]:>16s}: {score:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCMJW_6jibdX",
        "outputId": "baa2f416-6e5b-4ffb-8635-f9af98523437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: clip in /usr/local/lib/python3.12/dist-packages (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "# !pip install clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maaVzi5sirbb",
        "outputId": "431ce284-479f-4503-8ab6-2e6898c67981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.13)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.3.1\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-pq7mxpor\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-pq7mxpor\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (25.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (0.23.0+cu126)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=dc66a7d9dbb4f26024cf82f56f1c38a44ae0e9fea34186bb0a6d1b9bcb3eb73d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lp4lg7z6/wheels/35/3e/df/3d24cbfb3b6a06f17a2bfd7d1138900d4365d9028aa8f6e92f\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "  Attempting uninstall: clip\n",
            "    Found existing installation: clip 0.2.0\n",
            "    Uninstalling clip-0.2.0:\n",
            "      Successfully uninstalled clip-0.2.0\n",
            "Successfully installed clip-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ftfy regex\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSTaS5qdaA13",
        "outputId": "4709a81b-7f89-4dda-bd48-421b8edd3a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load checkpoint from /root/.cache/ImageReward/sac%2Blogos%2Bava1-l14-linearMSE.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 890M/890M [00:18<00:00, 51.1MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint loaded\n"
          ]
        }
      ],
      "source": [
        "# import ImageReward\n",
        "# Aes_model = ImageReward.load_score(name=\"Aesthetic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mq_bGY6b5cF"
      },
      "source": [
        "# 部署RM测试"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiYR0vgWb9Th"
      },
      "source": [
        "# 部署Flux.1测试"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9FfbWVoLWmN"
      },
      "source": [
        "# 分阶段Reward demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWh_zWJNfwX8"
      },
      "source": [
        "# 测试：Flux中间去噪+ImageReward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "4246ee10b10644ccb4ac4e217e758378",
            "7ffae593325f4e83a9742ff37f9fb824",
            "509ec565c2a54590937f98f8d53b8c2f",
            "7e1c58139cc34f80aae201bd653e75cd",
            "fe786ff2b80a4771973eab1cacb7575d",
            "06c6cff90ccf49ca99da64143492dc33",
            "af58aa6668da491c8f5a8f1835bfd0c1",
            "b26001163c20473694dda537614ca61c",
            "b339de8474f84cd8acfe533c449e452f",
            "71ff56ec3da24ec6b921bffabac30bda",
            "d3dc70b84cb5412c81d0b7582d54e82d",
            "5dcb2c3cfccd4518a6010e01b490e25e",
            "0e45882756d940a899e4ebe5a7ec4f8b",
            "33cfa73f55ac4ac0a58a26c22e6d3a52",
            "3563eee783bc43ba806f1f85266e8ef6",
            "82beaab3bd594050b8ce46ce3f7ac9e3",
            "b28f3bf9fb9e4133962c4788ff0708a1",
            "de9052db5c414e0e95c91d0f46da5b2b",
            "23272045d4164f199ad87dfa739c609a",
            "c54b4bc9d8af4c498c9d476786431f3c"
          ]
        },
        "id": "F4XZhdcF_IvG",
        "outputId": "2b56e248-2a2a-4c5c-c5ac-5333ea64e567"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4246ee10b10644ccb4ac4e217e758378"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfHSZX1GFcBs"
      },
      "source": [
        "这个代码的思路，就是 HierarchicalRewardModel 部署好Imagereward的AestheticScore分支，CLIPScore分支，BLIPScore分支，定义一个分阶段Reward。\n",
        "\n",
        "然后用Flux.1作为扩散模型，定义中间每5个step回调，计算带噪图的RM Score（这里先假设带噪图没有ood，关于带噪图rm，后面再改，先跑通），然后画一个reward curve，自变量是step，因变量是reward score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWDPaKxwFcBs"
      },
      "source": [
        "# 这个如果能跑，就说明HierarchicalRewardModel这个没问题，可以继续后面的逻辑"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9UemOVjfwJW",
        "outputId": "ec176113-ab71-4dfc-8bff-7348326504d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 890M/890M [00:08<00:00, 106MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load checkpoint from /root/.cache/ImageReward/ViT-L-14.pt\n",
            "checkpoint loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|███████                               | 695M/3.63G [00:32<02:02, 25.9MiB/s]"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Dict, Tuple, Callable\n",
        "import ImageReward as reward\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "from diffusers import FluxPipeline\n",
        "\n",
        "# 确保 ImageReward 模型的设备与 Flux.1 保持一致\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class HierarchicalRewardModel:\n",
        "    \"\"\"\n",
        "    分阶段奖励模型，根据扩散过程的不同阶段动态分配权重\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device: str = DEVICE):\n",
        "        self.device = device\n",
        "        self.setup_reward_models()\n",
        "\n",
        "    def setup_reward_models(self):\n",
        "        \"\"\"初始化各类奖励模型\"\"\"\n",
        "        self.clip_score_rm = reward.load_score(name=\"CLIP\")\n",
        "        self.blip_score_rm = reward.load_score(name=\"BLIP\")\n",
        "        self.aes_score_rm = reward.load_score(name=\"Aesthetic\")\n",
        "\n",
        "        # 权重配置\n",
        "        self.weight_config = {\n",
        "            'start': [0.5, 0.5, 0.0],  # [CLIP, BLIP, Aesthetic]\n",
        "            'end': [0.2, 0.2, 0.6]\n",
        "        }\n",
        "\n",
        "    def smooth_weight_transition(self, t: float, method: str = 'cosine') -> List[float]:\n",
        "        \"\"\"\n",
        "        设计平滑权重过渡函数\n",
        "\n",
        "        Args:\n",
        "            t: 时间步比例 [0, 1]，0表示开始，1表示结束\n",
        "            method: 过渡方法 ('linear', 'cosine', 'sigmoid', 'exponential')\n",
        "\n",
        "        Returns:\n",
        "            三个奖励模型的权重\n",
        "        \"\"\"\n",
        "        start_weights = np.array(self.weight_config['start'])\n",
        "        end_weights = np.array(self.weight_config['end'])\n",
        "\n",
        "        if method == 'linear':\n",
        "            alpha = t\n",
        "        elif method == 'cosine':\n",
        "            alpha = (1 - np.cos(np.pi * t)) / 2\n",
        "        elif method == 'sigmoid':\n",
        "            alpha = 1 / (1 + np.exp(-10 * (t - 0.5)))\n",
        "        elif method == 'exponential':\n",
        "            alpha = t ** 2\n",
        "        else:\n",
        "            alpha = t\n",
        "\n",
        "        weights = start_weights + alpha * (end_weights - start_weights)\n",
        "        weights = weights / np.sum(weights)\n",
        "\n",
        "        return weights.tolist()\n",
        "\n",
        "    def compute_hierarchical_reward(self, prompt: str, image: Image.Image, timestep: int,\n",
        "                                  total_steps: int = 50, method: str = 'cosine') -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        计算分阶段奖励\n",
        "\n",
        "        Args:\n",
        "            prompt: 文本提示词\n",
        "            image: PIL Image对象\n",
        "            timestep: 当前时间步\n",
        "            total_steps: 总时间步数\n",
        "            method: 权重过渡方法\n",
        "\n",
        "        Returns:\n",
        "            包含各项分数和综合分数的字典\n",
        "        \"\"\"\n",
        "        t = timestep / total_steps\n",
        "        weights = self.smooth_weight_transition(t, method)\n",
        "\n",
        "        # 使用临时文件来处理 ImageReward 的输入，确保资源被正确释放\n",
        "        image_path = None\n",
        "        try:\n",
        "            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:\n",
        "                image.save(tmp_file, format='JPEG')\n",
        "                image_path = tmp_file.name\n",
        "\n",
        "            # 计算各项分数\n",
        "            clip_score = self.clip_score_rm.score(prompt, image_path)\n",
        "            blip_score = self.blip_score_rm.score(prompt, image_path)\n",
        "            aes_score = self.aes_score_rm.score(prompt, image_path)\n",
        "\n",
        "            # 计算加权综合分数\n",
        "            hierarchical_score = (weights[0] * clip_score +\n",
        "                                  weights[1] * blip_score +\n",
        "                                  weights[2] * aes_score)\n",
        "\n",
        "            return {\n",
        "                'clip_score': clip_score,\n",
        "                'blip_score': blip_score,\n",
        "                'aesthetic_score': aes_score,\n",
        "                'hierarchical_score': hierarchical_score,\n",
        "                'weights': weights,\n",
        "                'timestep_ratio': t\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error computing reward for timestep {timestep}: {e}\")\n",
        "            # 如果发生错误，返回默认值\n",
        "            return {\n",
        "                'clip_score': 0.0,\n",
        "                'blip_score': 0.0,\n",
        "                'aesthetic_score': 0.0,\n",
        "                'hierarchical_score': 0.0,\n",
        "                'weights': weights,\n",
        "                'timestep_ratio': t\n",
        "            }\n",
        "        finally:\n",
        "            if image_path and os.path.exists(image_path):\n",
        "                os.unlink(image_path)\n",
        "\n",
        "def plot_reward_curves(all_results: Dict[str, List[Dict]]):\n",
        "    \"\"\"\n",
        "    绘制奖励曲线\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for key, results in all_results.items():\n",
        "        if results:\n",
        "            timesteps = [r['timestep_ratio'] for r in results]\n",
        "            hierarchical_scores = [r['hierarchical_score'] for r in results]\n",
        "            plt.plot(timesteps, hierarchical_scores, marker='o', linestyle='-', label=f\"Hierarchical Score ({key})\")\n",
        "\n",
        "    plt.title(\"Hierarchical Reward Score Over Flux.1 Diffusion Steps\")\n",
        "    plt.xlabel(\"Diffusion Progress (0 = Start, 1 = End)\")\n",
        "    plt.ylabel(\"Hierarchical Reward Score\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def run_evaluation_with_flux():\n",
        "    \"\"\"\n",
        "    驱动整个评估流程\n",
        "    \"\"\"\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    # 你的奖励模型实例\n",
        "    hrm = HierarchicalRewardModel(device=DEVICE)\n",
        "\n",
        "    # 1. 加载 Flux.1 模型\n",
        "    try:\n",
        "        pipe = FluxPipeline.from_pretrained(\n",
        "            \"black-forest-labs/flux.1-schnell\",\n",
        "            torch_dtype=torch.bfloat16\n",
        "        ).to(DEVICE)\n",
        "        print(\"Flux.1 pipeline loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading Flux.1: {e}\")\n",
        "        print(\"Please ensure you have logged in to Hugging Face and accepted the model's license.\")\n",
        "        return\n",
        "\n",
        "    # 2. 从数据集中加载提示词\n",
        "    print(\"Loading richhf-18k dataset for prompts...\")\n",
        "    try:\n",
        "        ds = load_dataset(\"Exploration/richhf_18k_with_images\")\n",
        "        data = ds['train']\n",
        "        prompts = [item['caption'] for item in data.select(range(5))]\n",
        "        print(f\"Loaded {len(prompts)} prompts.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {e}\")\n",
        "        return\n",
        "\n",
        "    # 3. 为每个提示词运行扩散过程并评估奖励\n",
        "    all_results = {}\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        print(f\"\\n--- Starting generation for prompt {i+1}/{len(prompts)} ---\")\n",
        "        print(f\"Prompt: {prompt[:80]}...\")\n",
        "\n",
        "        reward_history = []\n",
        "        total_steps = 50\n",
        "\n",
        "        def step_callback(step: int, timestep: int, latents: torch.FloatTensor):\n",
        "            if step % 5 == 0 or step == total_steps - 1:\n",
        "                print(f\"  Callback at step {step}/{total_steps-1}...\")\n",
        "                with torch.no_grad():\n",
        "                    latents_scaled = 1 / pipe.vae.config.scaling_factor * latents.to(pipe.vae.dtype)\n",
        "                    image_decoded_tensor = pipe.vae.decode(latents_scaled, return_dict=False)[0]\n",
        "                image_decoded = pipe.image_processor.postprocess(image_decoded_tensor, output_type=\"pil\")[0]\n",
        "\n",
        "                reward_info = hrm.compute_hierarchical_reward(\n",
        "                    prompt=prompt,\n",
        "                    image=image_decoded,\n",
        "                    timestep=step,\n",
        "                    total_steps=total_steps,\n",
        "                    method='cosine'\n",
        "                )\n",
        "                reward_history.append(reward_info)\n",
        "\n",
        "        # 运行管道，并传入回调函数\n",
        "        pipe(\n",
        "            prompt=prompt,\n",
        "            num_inference_steps=total_steps,\n",
        "            callback_on_step_end=step_callback,\n",
        "            callback_on_step_end_args={},\n",
        "            generator=torch.Generator(device=DEVICE).manual_seed(42 + i) # 使用不同种子以获得不同结果\n",
        "        )\n",
        "\n",
        "        all_results[f\"prompt_{i}\"] = reward_history\n",
        "        print(f\"Generation for prompt {i+1} completed.\")\n",
        "\n",
        "    # 4. 绘制所有结果\n",
        "    plot_reward_curves(all_results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_evaluation_with_flux()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDLROGH4Uj-r"
      },
      "outputs": [],
      "source": [
        "class LatentSpaceRMTuner:\n",
        "    \"\"\"潜在空间奖励模型微调器\"\"\"\n",
        "\n",
        "    def __init__(self, base_rm):\n",
        "        self.base_rm = base_rm\n",
        "\n",
        "    def create_latent_adapter(self, latent_dim: int = 512):\n",
        "        \"\"\"创建潜在空间适配器\"\"\"\n",
        "        class LatentAdapter(nn.Module):\n",
        "            def __init__(self, input_dim, output_dim):\n",
        "                super().__init__()\n",
        "                self.adapter = nn.Sequential(\n",
        "                    nn.Linear(input_dim, 256),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(0.1),\n",
        "                    nn.Linear(256, 128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(128, output_dim)\n",
        "                )\n",
        "\n",
        "            def forward(self, x):\n",
        "                return self.adapter(x)\n",
        "\n",
        "        return LatentAdapter(latent_dim, 1)\n",
        "\n",
        "    def prepare_latent_training_data(self, richhf_dataset, vae_encoder):\n",
        "        \"\"\"\n",
        "        准备潜在空间训练数据\n",
        "        解决OOD问题的关键是在潜在空间中训练奖励模型\n",
        "        \"\"\"\n",
        "        latent_features = []\n",
        "        reward_scores = []\n",
        "\n",
        "        for item in richhf_dataset:\n",
        "            # 将图像编码到潜在空间\n",
        "            with torch.no_grad():\n",
        "                latent = vae_encoder.encode(item['image']).latent_dist.sample()\n",
        "                latent = latent * 0.18215  # FLUX的缩放因子\n",
        "\n",
        "            # 计算多维度奖励分数作为监督信号\n",
        "            clip_score = self.base_rm.clip_score_rm.score(item['caption'], item['image'])\n",
        "            blip_score = self.base_rm.blip_score_rm.score(item['caption'], item['image'])\n",
        "            aes_score = self.base_rm.aes_score_rm.score(item['caption'], item['image'])\n",
        "\n",
        "            # 综合分数作为训练目标\n",
        "            combined_score = 0.3 * clip_score + 0.3 * blip_score + 0.4 * aes_score\n",
        "\n",
        "            latent_features.append(latent.flatten())\n",
        "            reward_scores.append(combined_score)\n",
        "\n",
        "        return torch.stack(latent_features), torch.tensor(reward_scores)\n",
        "\n",
        "    def train_latent_rm(self, train_loader, val_loader, epochs=100):\n",
        "        \"\"\"训练潜在空间奖励模型\"\"\"\n",
        "        latent_dim = train_loader.dataset[0][0].shape[0]\n",
        "        model = self.create_latent_adapter(latent_dim)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # 训练阶段\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            for batch_latent, batch_scores in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                pred_scores = model(batch_latent).squeeze()\n",
        "                loss = criterion(pred_scores, batch_scores)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            # 验证阶段\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for batch_latent, batch_scores in val_loader:\n",
        "                    pred_scores = model(batch_latent).squeeze()\n",
        "                    loss = criterion(pred_scores, batch_scores)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "            train_losses.append(train_loss / len(train_loader))\n",
        "            val_losses.append(val_loss / len(val_loader))\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                print(f'Epoch {epoch}: Train Loss = {train_losses[-1]:.4f}, Val Loss = {val_losses[-1]:.4f}')\n",
        "\n",
        "        return model, train_losses, val_losses"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4246ee10b10644ccb4ac4e217e758378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_af58aa6668da491c8f5a8f1835bfd0c1"
          }
        },
        "7ffae593325f4e83a9742ff37f9fb824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26001163c20473694dda537614ca61c",
            "placeholder": "​",
            "style": "IPY_MODEL_b339de8474f84cd8acfe533c449e452f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "509ec565c2a54590937f98f8d53b8c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_71ff56ec3da24ec6b921bffabac30bda",
            "placeholder": "​",
            "style": "IPY_MODEL_d3dc70b84cb5412c81d0b7582d54e82d",
            "value": ""
          }
        },
        "7e1c58139cc34f80aae201bd653e75cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_5dcb2c3cfccd4518a6010e01b490e25e",
            "style": "IPY_MODEL_0e45882756d940a899e4ebe5a7ec4f8b",
            "value": true
          }
        },
        "fe786ff2b80a4771973eab1cacb7575d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_33cfa73f55ac4ac0a58a26c22e6d3a52",
            "style": "IPY_MODEL_3563eee783bc43ba806f1f85266e8ef6",
            "tooltip": ""
          }
        },
        "06c6cff90ccf49ca99da64143492dc33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82beaab3bd594050b8ce46ce3f7ac9e3",
            "placeholder": "​",
            "style": "IPY_MODEL_b28f3bf9fb9e4133962c4788ff0708a1",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "af58aa6668da491c8f5a8f1835bfd0c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "b26001163c20473694dda537614ca61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b339de8474f84cd8acfe533c449e452f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71ff56ec3da24ec6b921bffabac30bda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3dc70b84cb5412c81d0b7582d54e82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dcb2c3cfccd4518a6010e01b490e25e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e45882756d940a899e4ebe5a7ec4f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33cfa73f55ac4ac0a58a26c22e6d3a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3563eee783bc43ba806f1f85266e8ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "82beaab3bd594050b8ce46ce3f7ac9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b28f3bf9fb9e4133962c4788ff0708a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de9052db5c414e0e95c91d0f46da5b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23272045d4164f199ad87dfa739c609a",
            "placeholder": "​",
            "style": "IPY_MODEL_c54b4bc9d8af4c498c9d476786431f3c",
            "value": "Connecting..."
          }
        },
        "23272045d4164f199ad87dfa739c609a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54b4bc9d8af4c498c9d476786431f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}